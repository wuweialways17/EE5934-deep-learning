{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011557,
     "end_time": "2021-04-18T23:56:50.022981",
     "exception": false,
     "start_time": "2021-04-18T23:56:50.011424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<font size = '6' >**Loading packages**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T23:56:50.045954Z",
     "iopub.status.busy": "2021-04-18T23:56:50.045229Z",
     "iopub.status.idle": "2021-04-18T23:59:17.833688Z",
     "shell.execute_reply": "2021-04-18T23:59:17.832676Z"
    },
    "papermill": {
     "duration": 147.80126,
     "end_time": "2021-04-18T23:59:17.833992",
     "exception": false,
     "start_time": "2021-04-18T23:56:50.032732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "import ast\n",
    "from glob import glob\n",
    "import zlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "!pip install /kaggle/input/kerasapplications -q\n",
    "!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps\n",
    "!pip install -q \"/kaggle/input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\"\n",
    "!pip install -q \"/kaggle/input/hpapytorchzoozip/pytorch_zoo-master\"\n",
    "!pip install -q \"/kaggle/input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master\"\n",
    "import hpacellseg.cellsegmentator as cellsegmentator\n",
    "from hpacellseg.utils import label_cell\n",
    "from pycocotools import _mask as coco_mask\n",
    "import efficientnet.keras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-18T23:59:17.862452Z",
     "iopub.status.busy": "2021-04-18T23:59:17.861728Z",
     "iopub.status.idle": "2021-04-18T23:59:17.864699Z",
     "shell.execute_reply": "2021-04-18T23:59:17.864082Z"
    },
    "papermill": {
     "duration": 0.020473,
     "end_time": "2021-04-18T23:59:17.864855",
     "exception": false,
     "start_time": "2021-04-18T23:59:17.844382",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PRESETS\n",
    "INT_2_STR = {0: 'Nucleoplasm', \n",
    "             1: 'Nuclear Membrane', \n",
    "             2: 'Nucleoli', \n",
    "             3: 'Nucleoli Fibrillar Center', \n",
    "             4: 'Nuclear Speckles', \n",
    "             5: 'Nuclear Bodies', \n",
    "             6: 'Endoplasmic Reticulum', \n",
    "             7: 'Golgi Apparatus', \n",
    "             8: 'Intermediate Filaments', \n",
    "             9: 'Actin Filaments', \n",
    "             10: 'Microtubules', \n",
    "             11: 'Mitotic Spindle', \n",
    "             12: 'Centrosome', \n",
    "             13: 'Plasma Membrane', \n",
    "             14: 'Mitochondria', \n",
    "             15: 'Aggresome', \n",
    "             16: 'Cytosol', \n",
    "             17: 'Vesicles', \n",
    "             18: 'Negative'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009497,
     "end_time": "2021-04-18T23:59:17.884400",
     "exception": false,
     "start_time": "2021-04-18T23:59:17.874903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<font size = '6' >**Define the paths**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T23:59:17.918176Z",
     "iopub.status.busy": "2021-04-18T23:59:17.917430Z",
     "iopub.status.idle": "2021-04-18T23:59:19.637789Z",
     "shell.execute_reply": "2021-04-18T23:59:19.637258Z"
    },
    "papermill": {
     "duration": 1.743724,
     "end_time": "2021-04-18T23:59:19.638035",
     "exception": false,
     "start_time": "2021-04-18T23:59:17.894311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... The number of testing images is 2236\n",
      "\t--> i.e. 559 4-channel images ...\n",
      "\n",
      "\n",
      "SAMPLE SUBMISSION DATAFRAME\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0040581b-f1f2-4fbe-b043-b6bfea5404bb</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0173029a-161d-40ef-af28-2342915b22fb</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 1 eNoLCAgIsAQABJ4Beg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>020a29cf-2c24-478b-8603-c22a90dc3e31</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 1 eNoLCAjJNgIABNkBkg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>fea47298-266a-4cf4-93bd-55d1bcc2fc7d</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 1 eNoLCAjJNgIABNkBkg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>ff069fa2-d948-408e-91b3-034cfea428d1</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 1 eNoLCAgIsAQABJ4Beg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>ff23eea9-4bbe-42af-a8da-9ae16321fc6d</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ID  ImageWidth  ImageHeight  \\\n",
       "0    0040581b-f1f2-4fbe-b043-b6bfea5404bb        2048         2048   \n",
       "4    0173029a-161d-40ef-af28-2342915b22fb        3072         3072   \n",
       "6    020a29cf-2c24-478b-8603-c22a90dc3e31        1728         1728   \n",
       "554  fea47298-266a-4cf4-93bd-55d1bcc2fc7d        1728         1728   \n",
       "557  ff069fa2-d948-408e-91b3-034cfea428d1        3072         3072   \n",
       "558  ff23eea9-4bbe-42af-a8da-9ae16321fc6d        2048         2048   \n",
       "\n",
       "             PredictionString  \n",
       "0    0 1 eNoLCAgIMAEABJkBdQ==  \n",
       "4    0 1 eNoLCAgIsAQABJ4Beg==  \n",
       "6    0 1 eNoLCAjJNgIABNkBkg==  \n",
       "554  0 1 eNoLCAjJNgIABNkBkg==  \n",
       "557  0 1 eNoLCAgIsAQABJ4Beg==  \n",
       "558  0 1 eNoLCAgIMAEABJkBdQ==  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TEST DATAFRAME W/ MASKS\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>mask_rles</th>\n",
       "      <th>mask_bboxes</th>\n",
       "      <th>mask_sub_rles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0040581b-f1f2-4fbe-b043-b6bfea5404bb</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "      <td>[729089 8 729109 12 731137 8 731157 12 733185 ...</td>\n",
       "      <td>[(356, 0, 1076, 244), (764, 0, 1456, 756), (15...</td>\n",
       "      <td>[eNqtVL0OgyAQfiVIz4TBoYODiVdKE2odGDqYRi1p338rr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0173029a-161d-40ef-af28-2342915b22fb</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 1 eNoLCAgIsAQABJ4Beg==</td>\n",
       "      <td>[1 558 3073 558 6145 558 9217 558 12289 558 15...</td>\n",
       "      <td>[(0, 0, 672, 624), (258, 0, 882, 318), (882, 0...</td>\n",
       "      <td>[eNq9VMEKwjAM/aVQsE7ZRSgbCKVzh1mnVK1zjjH0/296c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>020a29cf-2c24-478b-8603-c22a90dc3e31</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 1 eNoLCAjJNgIABNkBkg==</td>\n",
       "      <td>[180 118 1908 118 3636 118 5364 118 7092 115 8...</td>\n",
       "      <td>[(0, 0, 733, 297), (1060, 0, 1303, 85), (1087,...</td>\n",
       "      <td>[eNq1lltvqzAMgP8SDtmZtKcjHWlSN+KulG3QJlzCpdBS+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>fea47298-266a-4cf4-93bd-55d1bcc2fc7d</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 1 eNoLCAjJNgIABNkBkg==</td>\n",
       "      <td>[2555936 17 2557664 17 2559392 17 2561090 64 2...</td>\n",
       "      <td>[(1479, 0, 1728, 341), (736, 31, 1367, 827), (...</td>\n",
       "      <td>[eNqFUMEOgjAM/aU3tzijN02IIxtDEhJPgEajJ/3/m6xlM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>ff069fa2-d948-408e-91b3-034cfea428d1</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 1 eNoLCAgIsAQABJ4Beg==</td>\n",
       "      <td>[2377891 60 2380963 60 2384035 60 2387107 60 2...</td>\n",
       "      <td>[(774, 0, 1674, 402), (1338, 0, 2244, 810), (1...</td>\n",
       "      <td>[eNoLCk2KMMoxDMkzMoCBNL8gowh/ONcrycAFzonzz0Piu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>ff23eea9-4bbe-42af-a8da-9ae16321fc6d</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "      <td>[1 268 349 80 2049 268 2397 80 4097 268 4445 8...</td>\n",
       "      <td>[(0, 0, 244, 528), (180, 0, 504, 636), (728, 0...</td>\n",
       "      <td>[eNq9ksFqwzAMhl8pauPNHTkMVmjxGkUwH3QwtQI+6OD3P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ID  ImageWidth  ImageHeight  \\\n",
       "0    0040581b-f1f2-4fbe-b043-b6bfea5404bb        2048         2048   \n",
       "4    0173029a-161d-40ef-af28-2342915b22fb        3072         3072   \n",
       "6    020a29cf-2c24-478b-8603-c22a90dc3e31        1728         1728   \n",
       "554  fea47298-266a-4cf4-93bd-55d1bcc2fc7d        1728         1728   \n",
       "557  ff069fa2-d948-408e-91b3-034cfea428d1        3072         3072   \n",
       "558  ff23eea9-4bbe-42af-a8da-9ae16321fc6d        2048         2048   \n",
       "\n",
       "             PredictionString  \\\n",
       "0    0 1 eNoLCAgIMAEABJkBdQ==   \n",
       "4    0 1 eNoLCAgIsAQABJ4Beg==   \n",
       "6    0 1 eNoLCAjJNgIABNkBkg==   \n",
       "554  0 1 eNoLCAjJNgIABNkBkg==   \n",
       "557  0 1 eNoLCAgIsAQABJ4Beg==   \n",
       "558  0 1 eNoLCAgIMAEABJkBdQ==   \n",
       "\n",
       "                                             mask_rles  \\\n",
       "0    [729089 8 729109 12 731137 8 731157 12 733185 ...   \n",
       "4    [1 558 3073 558 6145 558 9217 558 12289 558 15...   \n",
       "6    [180 118 1908 118 3636 118 5364 118 7092 115 8...   \n",
       "554  [2555936 17 2557664 17 2559392 17 2561090 64 2...   \n",
       "557  [2377891 60 2380963 60 2384035 60 2387107 60 2...   \n",
       "558  [1 268 349 80 2049 268 2397 80 4097 268 4445 8...   \n",
       "\n",
       "                                           mask_bboxes  \\\n",
       "0    [(356, 0, 1076, 244), (764, 0, 1456, 756), (15...   \n",
       "4    [(0, 0, 672, 624), (258, 0, 882, 318), (882, 0...   \n",
       "6    [(0, 0, 733, 297), (1060, 0, 1303, 85), (1087,...   \n",
       "554  [(1479, 0, 1728, 341), (736, 31, 1367, 827), (...   \n",
       "557  [(774, 0, 1674, 402), (1338, 0, 2244, 810), (1...   \n",
       "558  [(0, 0, 244, 528), (180, 0, 504, 636), (728, 0...   \n",
       "\n",
       "                                         mask_sub_rles  \n",
       "0    [eNqtVL0OgyAQfiVIz4TBoYODiVdKE2odGDqYRi1p338rr...  \n",
       "4    [eNq9VMEKwjAM/aVQsE7ZRSgbCKVzh1mnVK1zjjH0/296c...  \n",
       "6    [eNq1lltvqzAMgP8SDtmZtKcjHWlSN+KulG3QJlzCpdBS+...  \n",
       "554  [eNqFUMEOgjAM/aU3tzijN02IIxtDEhJPgEajJ/3/m6xlM...  \n",
       "557  [eNoLCk2KMMoxDMkzMoCBNL8gowh/ONcrycAFzonzz0Piu...  \n",
       "558  [eNq9ksFqwzAMhl8pauPNHTkMVmjxGkUwH3QwtQI+6OD3P...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define paths to nucleus and cell models for the cellsegmentator class\n",
    "NUC_MODEL = '/kaggle/input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth'\n",
    "CELL_MODEL = '/kaggle/input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth'\n",
    "\n",
    "#main_model = \"../input/xception-model/ckpt-0008-0.0595.ckpt\"\n",
    "auxiliary_model = \"../input/efnb7-model/efbn7_model_20_green.h5\"\n",
    "main_model = \"../input/xception-model/final/0004-0.0652.ckpt\"\n",
    "\n",
    "# Define the path to the competition data directory\n",
    "DATA_DIR = \"/kaggle/input/hpa-single-cell-image-classification\"\n",
    "\n",
    "# Define the paths to the training and testing tfrecord and \n",
    "# image folders respectively for the competition data\n",
    "TEST_IMG_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "# Capture all the relevant full image paths for the competition dataset\n",
    "TEST_IMG_PATHS = sorted([os.path.join(TEST_IMG_DIR, f_name) for f_name in os.listdir(TEST_IMG_DIR)])\n",
    "print(f\"... The number of testing images is {len(TEST_IMG_PATHS)}\" \\\n",
    "      f\"\\n\\t--> i.e. {len(TEST_IMG_PATHS)//4} 4-channel images ...\")\n",
    "\n",
    "# Define paths to the relevant csv files\n",
    "PUB_SS_CSV = \"/kaggle/input/hpa-sample-submission-with-extra-metadata/updated_sample_submission.csv\"\n",
    "SWAP_SS_CSV = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "# Create the relevant dataframe objects\n",
    "ss_df = pd.read_csv(SWAP_SS_CSV)\n",
    "\n",
    "# Test Time Augmentation Information\n",
    "DO_TTA = True\n",
    "TTA_REPEATS = 8\n",
    "\n",
    "# helps us control whether this is the full submission or just the initial pass\n",
    "IS_DEMO = len(ss_df)==559\n",
    "\n",
    "if IS_DEMO:\n",
    "    ss_df_1 = ss_df.drop_duplicates(\"ImageWidth\", keep=\"first\")\n",
    "    ss_df_2 = ss_df.drop_duplicates(\"ImageWidth\", keep=\"last\")\n",
    "    ss_df = pd.concat([ss_df_1, ss_df_2])\n",
    "    del ss_df_1; del ss_df_2; gc.collect();\n",
    "    print(\"\\n\\nSAMPLE SUBMISSION DATAFRAME\\n\\n\")\n",
    "    display(ss_df)\n",
    "else:\n",
    "    print(\"\\n\\nSAMPLE SUBMISSION DATAFRAME\\n\\n\")\n",
    "    display(ss_df)\n",
    "    \n",
    "# If demo-submission/display we only do a subset of the data\n",
    "ONLY_PUBLIC = True\n",
    "if ONLY_PUBLIC:\n",
    "    pub_ss_df = pd.read_csv(PUB_SS_CSV)\n",
    "    \n",
    "    if IS_DEMO:\n",
    "        pub_ss_df_1 = pub_ss_df.drop_duplicates(\"ImageWidth\", keep=\"first\")\n",
    "        pub_ss_df_2 = pub_ss_df.drop_duplicates(\"ImageWidth\", keep=\"last\")\n",
    "        pub_ss_df = pd.concat([pub_ss_df_1, pub_ss_df_2])\n",
    "        \n",
    "    pub_ss_df.mask_rles = pub_ss_df.mask_rles.apply(lambda x: ast.literal_eval(x))\n",
    "    pub_ss_df.mask_bboxes = pub_ss_df.mask_bboxes.apply(lambda x: ast.literal_eval(x))\n",
    "    pub_ss_df.mask_sub_rles = pub_ss_df.mask_sub_rles.apply(lambda x: ast.literal_eval(x))\n",
    "    \n",
    "    print(\"\\n\\nTEST DATAFRAME W/ MASKS\\n\\n\")\n",
    "    display(pub_ss_df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012259,
     "end_time": "2021-04-18T23:59:19.663600",
     "exception": false,
     "start_time": "2021-04-18T23:59:19.651341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<font size = '6' >**Helper function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-04-18T23:59:19.728217Z",
     "iopub.status.busy": "2021-04-18T23:59:19.727382Z",
     "iopub.status.idle": "2021-04-18T23:59:19.730803Z",
     "shell.execute_reply": "2021-04-18T23:59:19.730172Z"
    },
    "papermill": {
     "duration": 0.054942,
     "end_time": "2021-04-18T23:59:19.731014",
     "exception": false,
     "start_time": "2021-04-18T23:59:19.676072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def binary_mask_to_ascii(mask, mask_val=1):\n",
    "    \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n",
    "    mask = np.where(mask==mask_val, 1, 0).astype(np.bool)\n",
    "    \n",
    "    # check input mask --\n",
    "    if mask.dtype != np.bool:\n",
    "        raise ValueError(f\"encode_binary_mask expects a binary mask, received dtype == {mask.dtype}\")\n",
    "\n",
    "    mask = np.squeeze(mask)\n",
    "    if len(mask.shape) != 2:\n",
    "        raise ValueError(f\"encode_binary_mask expects a 2d mask, received shape == {mask.shape}\")\n",
    "\n",
    "    # convert input mask to expected COCO API input --\n",
    "    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "    mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "    # RLE encode mask --\n",
    "    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "    # compress and base64 encoding --\n",
    "    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "    base64_str = base64.b64encode(binary_str)\n",
    "    return base64_str.decode()\n",
    "\n",
    "\n",
    "def rle_encoding(img, mask_val=1):\n",
    "    \"\"\"\n",
    "    Turns our masks into RLE encoding to easily store them\n",
    "    and feed them into models later on\n",
    "    https://en.wikipedia.org/wiki/Run-length_encoding\n",
    "    \n",
    "    Args:\n",
    "        img (np.array): Segmentation array\n",
    "        mask_val (int): Which value to use to create the RLE\n",
    "        \n",
    "    Returns:\n",
    "        RLE string\n",
    "    \n",
    "    \"\"\"\n",
    "    dots = np.where(img.T.flatten() == mask_val)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "        \n",
    "    return ' '.join([str(x) for x in run_lengths])\n",
    "\n",
    "\n",
    "def rle_to_mask(rle_string, height, width):\n",
    "    \"\"\" Convert RLE sttring into a binary mask \n",
    "    \n",
    "    Args:\n",
    "        rle_string (rle_string): Run length encoding containing \n",
    "            segmentation mask information\n",
    "        height (int): Height of the original image the map comes from\n",
    "        width (int): Width of the original image the map comes from\n",
    "    \n",
    "    Returns:\n",
    "        Numpy array of the binary segmentation mask for a given cell\n",
    "    \"\"\"\n",
    "    rows,cols = height,width\n",
    "    rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n",
    "    rle_pairs = np.array(rle_numbers).reshape(-1,2)\n",
    "    img = np.zeros(rows*cols,dtype=np.uint8)\n",
    "    for index,length in rle_pairs:\n",
    "        index -= 1\n",
    "        img[index:index+length] = 255\n",
    "    img = img.reshape(cols,rows)\n",
    "    img = img.T\n",
    "    return img\n",
    "\n",
    "\n",
    "def decode_img(img, img_size=(224,224), testing=False):\n",
    "\n",
    "    \n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    if not testing:\n",
    "        # resize the image to the desired size\n",
    "        img = tf.image.decode_png(img, channels=1)\n",
    "        return tf.cast(tf.image.resize(img, img_size), tf.uint8)\n",
    "    else:\n",
    "        return tf.image.decode_png(img, channels=1)\n",
    "        \n",
    "      \n",
    "    \n",
    "    \n",
    "def create_pred_col(row):\n",
    "    \"\"\" Simple function to return the correct prediction string\n",
    "    \n",
    "    We will want the original public test dataframe submission when it is \n",
    "    available. However, we will use the swapped inn submission dataframe\n",
    "    when it is not.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): A row in the dataframe\n",
    "    \n",
    "    Returns:\n",
    "        The prediction string\n",
    "    \"\"\"\n",
    "    if pd.isnull(row.PredictionString_y):\n",
    "        return row.PredictionString_x\n",
    "    else:\n",
    "        return row.PredictionString_y\n",
    "    \n",
    "    \n",
    "def load_image(img_id, img_dir, testing=False, only_public=False):\n",
    "    \"\"\" Load An Image Using ID and Directory Path - Composes 4 Individual Images \"\"\"\n",
    "    if only_public:\n",
    "        return_axis = -1\n",
    "        clr_list = [\"red\", \"green\", \"blue\"]\n",
    "    else:\n",
    "        return_axis = 0\n",
    "        clr_list = [\"red\", \"green\", \"blue\", \"yellow\"]\n",
    "    \n",
    "    if not testing:\n",
    "        rgby = [\n",
    "            np.asarray(Image.open(os.path.join(img_dir, img_id+f\"_{c}.png\")), np.uint8) \\\n",
    "            for c in [\"red\", \"green\", \"blue\", \"yellow\"]\n",
    "        ]\n",
    "        return np.stack(rgby, axis=-1)\n",
    "    else:\n",
    "        # This is for cellsegmentator\n",
    "        return np.stack(\n",
    "            [np.asarray(decode_img(tf.io.read_file(os.path.join(img_dir, img_id+f\"_{c}.png\")), testing=True), np.uint8)[..., 0] \\\n",
    "             for c in clr_list], axis=return_axis,\n",
    "        )\n",
    "        \n",
    "    \n",
    "    \n",
    "def convert_rgby_to_rgb(arr):\n",
    "    \"\"\" Convert a 4 channel (RGBY) image to a 3 channel RGB image.\n",
    "    \n",
    "    Advice From Competition Host/User: lnhtrang\n",
    "\n",
    "    For annotation (by experts) and for the model, I guess we agree that individual \n",
    "    channels with full range px values are better. \n",
    "    In annotation, we toggled the channels. \n",
    "    For visualization purpose only, you can try blending the channels. \n",
    "    For example, \n",
    "        - red = red + yellow\n",
    "        - green = green + yellow/2\n",
    "        - blue=blue.\n",
    "        \n",
    "    Args:\n",
    "        arr (numpy array): The RGBY, 4 channel numpy array for a given image\n",
    "    \n",
    "    Returns:\n",
    "        RGB Image\n",
    "    \"\"\"\n",
    "    \n",
    "    rgb_arr = np.zeros_like(arr[..., :-1])\n",
    "    rgb_arr[..., 0] = arr[..., 0]\n",
    "    rgb_arr[..., 1] = arr[..., 1]+arr[..., 3]/2\n",
    "    rgb_arr[..., 2] = arr[..., 2]\n",
    "    \n",
    "    return rgb_arr\n",
    "\n",
    "    \n",
    "    \n",
    "def flatten_list_of_lists(l_o_l, to_string=False):\n",
    "    if not to_string:\n",
    "        return [item for sublist in l_o_l for item in sublist]\n",
    "    else:\n",
    "        return [str(item) for sublist in l_o_l for item in sublist]\n",
    "\n",
    "    \n",
    "\n",
    "def get_contour_bbox_from_raw(raw_mask):\n",
    "    \"\"\" Get bbox of contour as `xmin ymin xmax ymax`\n",
    "    \n",
    "    Args:\n",
    "        raw_mask (nparray): Numpy array containing segmentation mask information\n",
    "    \n",
    "    Returns:\n",
    "        Numpy array for a cell bounding box coordinates\n",
    "    \"\"\"\n",
    "    cnts = grab_contours(\n",
    "        cv2.findContours(\n",
    "            raw_mask, \n",
    "            cv2.RETR_EXTERNAL, \n",
    "            cv2.CHAIN_APPROX_SIMPLE\n",
    "        ))\n",
    "    xywhs = [cv2.boundingRect(cnt) for cnt in cnts]\n",
    "    xys = [(xywh[0], xywh[1], xywh[0]+xywh[2], xywh[1]+xywh[3]) for xywh in xywhs]\n",
    "    return sorted(xys, key=lambda x: (x[1], x[0]))\n",
    "\n",
    "\n",
    "def pad_to_square(a):\n",
    "    \"\"\" Pad an array `a` evenly until it is a square \"\"\"\n",
    "    if a.shape[1]>a.shape[0]: # pad height\n",
    "        n_to_add = a.shape[1]-a.shape[0]\n",
    "        top_pad = n_to_add//2\n",
    "        bottom_pad = n_to_add-top_pad\n",
    "        a = np.pad(a, [(top_pad, bottom_pad), (0, 0), (0, 0)], mode='constant')\n",
    "\n",
    "    elif a.shape[0]>a.shape[1]: # pad width\n",
    "        n_to_add = a.shape[0]-a.shape[1]\n",
    "        left_pad = n_to_add//2\n",
    "        right_pad = n_to_add-left_pad\n",
    "        a = np.pad(a, [(0, 0), (left_pad, right_pad), (0, 0)], mode='constant')\n",
    "    else:\n",
    "        pass\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "def grab_contours(cnts):\n",
    "    # if the length the contours tuple returned by cv2.findContours\n",
    "    # is '2' then we are using either OpenCV v2.4, v4-beta, or\n",
    "    # v4-official\n",
    "    if len(cnts) == 2:\n",
    "        cnts = cnts[0]\n",
    "\n",
    "    # if the length of the contours tuple is '3' then we are using\n",
    "    # either OpenCV v3, v4-pre, or v4-alpha\n",
    "    elif len(cnts) == 3:\n",
    "        cnts = cnts[1]\n",
    "\n",
    "    # otherwise OpenCV has changed their cv2.findContours return\n",
    "    # signature yet again and I have no idea WTH is going on\n",
    "    else:\n",
    "        raise Exception((\"Contours tuple must have length 2 or 3, \"\n",
    "            \"otherwise OpenCV changed their cv2.findContours return \"\n",
    "            \"signature yet again. Refer to OpenCV's documentation \"\n",
    "            \"in that case\"))\n",
    "\n",
    "    # return the actual contours array\n",
    "    return cnts\n",
    "\n",
    "    \n",
    "def tta(original_img_batch, repeats=4):\n",
    "    \"\"\" Perform test time augmentation \"\"\"\n",
    "    tta_img_batches = [original_img_batch,]\n",
    "\n",
    "    for i in range(repeats):\n",
    "        # create new image batch (tf automatically deep copies)\n",
    "        img_batch = original_img_batch\n",
    "        \n",
    "        SEED = tf.random.uniform((2,), minval=0, maxval=100, dtype=tf.dtypes.int32)\n",
    "        K = tf.random.uniform((1,), minval=0, maxval=4, dtype=tf.dtypes.int32)[0]\n",
    "\n",
    "        img_batch = tf.image.stateless_random_flip_left_right(img_batch, SEED)\n",
    "        img_batch = tf.image.stateless_random_flip_up_down(img_batch, SEED)\n",
    "        img_batch = tf.image.rot90(img_batch, K)\n",
    "\n",
    "        img_batch = tf.image.stateless_random_saturation(img_batch, 0.9, 1.1, SEED)\n",
    "        img_batch = tf.image.stateless_random_brightness(img_batch, 0.075, SEED)\n",
    "        img_batch = tf.image.stateless_random_contrast(img_batch, 0.9, 1.1, SEED)    \n",
    "        tta_img_batches.append(img_batch)\n",
    "    \n",
    "    return tta_img_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012184,
     "end_time": "2021-04-18T23:59:19.755711",
     "exception": false,
     "start_time": "2021-04-18T23:59:19.743527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<font size = '6' >**Load the model**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T23:59:19.790706Z",
     "iopub.status.busy": "2021-04-18T23:59:19.789922Z",
     "iopub.status.idle": "2021-04-18T23:59:32.983819Z",
     "shell.execute_reply": "2021-04-18T23:59:32.982662Z"
    },
    "papermill": {
     "duration": 13.215749,
     "end_time": "2021-04-18T23:59:32.983994",
     "exception": false,
     "start_time": "2021-04-18T23:59:19.768245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load inference model\n",
    "inference_model = tf.keras.models.load_model(main_model,compile=False)\n",
    "\n",
    "# Parameters\n",
    "IMAGE_SIZES = [1728, 2048, 3072, 4096]\n",
    "BATCH_SIZE = 8\n",
    "CONF_THRESH = 0.0\n",
    "TILE_SIZE = (224,224)\n",
    "\n",
    "\n",
    "# Switch what we will be actually infering on\n",
    "if ONLY_PUBLIC:\n",
    "    # Make subset dataframes\n",
    "    predict_df_1728 = pub_ss_df[pub_ss_df.ImageWidth==IMAGE_SIZES[0]]\n",
    "    predict_df_2048 = pub_ss_df[pub_ss_df.ImageWidth==IMAGE_SIZES[1]]\n",
    "    predict_df_3072 = pub_ss_df[pub_ss_df.ImageWidth==IMAGE_SIZES[2]]\n",
    "    predict_df_4096 = pub_ss_df[pub_ss_df.ImageWidth==IMAGE_SIZES[3]]\n",
    "else:\n",
    "    # Load Segmentator\n",
    "    segmentator = cellsegmentator.CellSegmentator(NUC_MODEL, CELL_MODEL, scale_factor=0.25, padding=True)\n",
    "    \n",
    "    # Make subset dataframes\n",
    "    predict_df_1728 = ss_df[ss_df.ImageWidth==IMAGE_SIZES[0]]\n",
    "    predict_df_2048 = ss_df[ss_df.ImageWidth==IMAGE_SIZES[1]]\n",
    "    predict_df_3072 = ss_df[ss_df.ImageWidth==IMAGE_SIZES[2]]\n",
    "    predict_df_4096 = ss_df[ss_df.ImageWidth==IMAGE_SIZES[3]]\n",
    "\n",
    "\n",
    "predict_ids_1728 = predict_df_1728.ID.to_list()\n",
    "predict_ids_2048 = predict_df_2048.ID.to_list()\n",
    "predict_ids_3072 = predict_df_3072.ID.to_list()\n",
    "predict_ids_4096 = predict_df_4096.ID.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012322,
     "end_time": "2021-04-18T23:59:33.009212",
     "exception": false,
     "start_time": "2021-04-18T23:59:32.996890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<font size = '6' >**Ensemble inference**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T23:59:33.048832Z",
     "iopub.status.busy": "2021-04-18T23:59:33.045200Z",
     "iopub.status.idle": "2021-04-19T00:02:12.206184Z",
     "shell.execute_reply": "2021-04-19T00:02:12.201891Z"
    },
    "papermill": {
     "duration": 159.184181,
     "end_time": "2021-04-19T00:02:12.206355",
     "exception": false,
     "start_time": "2021-04-18T23:59:33.022174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...WORKING ON IMAGE IDS FOR SIZE 1728 ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8b4f0d94934f7d8a0dcc2ec71bd664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...WORKING ON IMAGE IDS FOR SIZE 2048 ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7580b5272e914c46ac8b1a1b151a2ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...WORKING ON IMAGE IDS FOR SIZE 3072 ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f9eb0a569b4503bc413b1e70ce675b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...SKIPPING SIZE 4096 AS THERE ARE NO IMAGE IDS ...\n",
      "\n",
      "\n",
      "... TEST DATAFRAME ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>020a29cf-2c24-478b-8603-c22a90dc3e31</td>\n",
       "      <td>0 0.0104 eNq1lltvqzAMgP8SDtmZtKcjHWlSN+KulG3QJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fea47298-266a-4cf4-93bd-55d1bcc2fc7d</td>\n",
       "      <td>0 0.0048 eNqFUMEOgjAM/aU3tzijN02IIxtDEhJPgEajJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0040581b-f1f2-4fbe-b043-b6bfea5404bb</td>\n",
       "      <td>0 0.0339 eNqtVL0OgyAQfiVIz4TBoYODiVdKE2odGDqYR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "0  020a29cf-2c24-478b-8603-c22a90dc3e31   \n",
       "1  fea47298-266a-4cf4-93bd-55d1bcc2fc7d   \n",
       "2  0040581b-f1f2-4fbe-b043-b6bfea5404bb   \n",
       "\n",
       "                                    PredictionString  \n",
       "0  0 0.0104 eNq1lltvqzAMgP8SDtmZtKcjHWlSN+KulG3QJ...  \n",
       "1  0 0.0048 eNqFUMEOgjAM/aU3tzijN02IIxtDEhJPgEajJ...  \n",
       "2  0 0.0339 eNqtVL0OgyAQfiVIz4TBoYODiVdKE2odGDqYR...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "sub_df = pd.DataFrame(columns=[\"ID\"], data=predict_ids_1728+predict_ids_2048+predict_ids_3072+predict_ids_4096)\n",
    "\n",
    "\n",
    "for size_idx, submission_ids in enumerate([predict_ids_1728, predict_ids_2048, predict_ids_3072, predict_ids_4096]):\n",
    "    size = IMAGE_SIZES[size_idx]\n",
    "    if submission_ids==[]:\n",
    "        print(f\"\\n...SKIPPING SIZE {size} AS THERE ARE NO IMAGE IDS ...\\n\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"\\n...WORKING ON IMAGE IDS FOR SIZE {size} ...\\n\")\n",
    "    for i in tqdm(range(0, len(submission_ids), BATCH_SIZE), total=int(np.ceil(len(submission_ids)/BATCH_SIZE))):\n",
    "        \n",
    "        # Step 0: Get batch of images as numpy arrays\n",
    "        batch_rgby_images = [\n",
    "            load_image(ID, TEST_IMG_DIR, testing=True, only_public=ONLY_PUBLIC) \\\n",
    "            for ID in submission_ids[i:(i+BATCH_SIZE)]\n",
    "        ]\n",
    "        \n",
    "        if ONLY_PUBLIC:\n",
    "            # Step 1: Get Bounding Boxes\n",
    "            batch_cell_bboxes = pub_ss_df[pub_ss_df.ID.isin(submission_ids[i:(i+BATCH_SIZE)])].mask_bboxes.values\n",
    "            \n",
    "            # Step 2: Get RGB Images (which are actually just labelled as RGBY)\n",
    "            batch_rgb_images = batch_rgby_images\n",
    "            \n",
    "            # Step 3: Get Submission RLEs\n",
    "            submission_rles = pub_ss_df[pub_ss_df.ID.isin(submission_ids[i:(i+BATCH_SIZE)])].mask_sub_rles.values\n",
    "            \n",
    "            # Optional Step: Get the Masks\n",
    "            if IS_DEMO:\n",
    "                batch_masks = [\n",
    "                    sum([rle_to_mask(mask, size, size) for mask in batch]) \\\n",
    "                    for batch in pub_ss_df[pub_ss_df.ID.isin(submission_ids[i:(i+BATCH_SIZE)])].mask_rles.values\n",
    "                ]\n",
    "                \n",
    "            \n",
    "        else:\n",
    "            # Step 1: Do Prediction On Batch\n",
    "            cell_segmentations = segmentator.pred_cells([[rgby_image[j] for rgby_image in batch_rgby_images] for j in [0, 3, 2]])\n",
    "            nuc_segmentations = segmentator.pred_nuclei([rgby_image[2] for rgby_image in batch_rgby_images])\n",
    "\n",
    "            # Step 2: Perform Cell Labelling on Batch\n",
    "            batch_masks = [label_cell(nuc_seg, cell_seg)[1].astype(np.uint8) for nuc_seg, cell_seg in zip(nuc_segmentations, cell_segmentations)]\n",
    "\n",
    "            # Step 3: Reshape the RGBY Images so They Are Channels Last Across the Batch\n",
    "            batch_rgb_images = [rgby_image.transpose(1,2,0)[..., :-1] for rgby_image in batch_rgby_images]\n",
    "\n",
    "            # Step 4: Get Bounding Boxes For All Cells in All Images in Batch\n",
    "            batch_cell_bboxes = [get_contour_bbox_from_raw(mask) for mask in batch_masks]\n",
    "            \n",
    "            # Step 5: Generate Submission RLEs For the Batch\n",
    "            submission_rles = [[binary_mask_to_ascii(mask, mask_val=cell_id) for cell_id in range(1, mask.max()+1)] for mask in batch_masks]\n",
    "    \n",
    "        # Step 6: Cut Out, Pad to Square, and Resize to 224x224\n",
    "        batch_cell_tiles = [[\n",
    "            cv2.resize(\n",
    "                pad_to_square(\n",
    "                    rgb_image[bbox[1]:bbox[3], bbox[0]:bbox[2], ...]), \n",
    "                TILE_SIZE, interpolation=cv2.INTER_CUBIC) for bbox in bboxes] \n",
    "            for bboxes, rgb_image in zip(batch_cell_bboxes, batch_rgb_images)\n",
    "        ]\n",
    "\n",
    "        # Step 7: (OPTIONAL) Test Time Augmentation\n",
    "        if DO_TTA:\n",
    "            tta_batch_cell_tiles = [tta(tf.cast(ct, dtype=tf.float32), repeats=TTA_REPEATS) for ct in batch_cell_tiles]\n",
    "        else:\n",
    "            batch_cell_tiles = [tf.cast(ct, dtype=tf.float32) for ct in batch_cell_tiles]\n",
    "        \n",
    "        # Step 8: Perform Inference \n",
    "        if DO_TTA:\n",
    "            tta_batch_o_preds = [[inference_model.predict(ct) for ct in bct] for bct in tta_batch_cell_tiles]\n",
    "            batch_o_preds = [tf.keras.layers.Average()(tta_o_preds).numpy() for tta_o_preds in tta_batch_o_preds]\n",
    "        else:\n",
    "            batch_o_preds = [inference_model.predict(cell_tiles) for cell_tiles in batch_cell_tiles]\n",
    "            \n",
    "        # Step 9: Post-Process\n",
    "        batch_confs = [[pred[np.where(pred>CONF_THRESH)] for pred in o_preds] for o_preds in batch_o_preds]\n",
    "        batch_preds = [[np.where(pred>CONF_THRESH)[0] for pred in o_preds] for o_preds in batch_o_preds]\n",
    "\n",
    "        for j, preds in enumerate(batch_preds):\n",
    "            for k in range(len(preds)):\n",
    "                if preds[k].size==0:\n",
    "                    batch_preds[j][k]=np.array([18,])\n",
    "                    batch_confs[j][k]=np.array([1-np.max(batch_o_preds[j][k]),])\n",
    "\n",
    "        \n",
    "        # Step 10: Format Predictions To Create Prediction String Easily\n",
    "        submission_rles = [flatten_list_of_lists([[m,]*len(p) for m, p in zip(masks, preds)]) for masks, preds in zip(submission_rles, batch_preds)]\n",
    "        batch_preds = [flatten_list_of_lists(preds, to_string=True) for preds in batch_preds]\n",
    "        batch_confs = [[f\"{conf:.4f}\" for cell_confs in confs for conf in cell_confs] for confs in batch_confs]\n",
    "        \n",
    "        # Step 11: Save Predictions to Be Added to Dataframe At The End\n",
    "        predictions.extend([\" \".join(flatten_list_of_lists(zip(*[preds,confs,masks]))) for preds, confs, masks in zip(batch_preds, batch_confs, submission_rles)])\n",
    "sub_df[\"PredictionString\"] = predictions\n",
    "\n",
    "print(\"\\n... TEST DATAFRAME ...\\n\")\n",
    "display(sub_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T00:02:12.252129Z",
     "iopub.status.busy": "2021-04-19T00:02:12.249182Z",
     "iopub.status.idle": "2021-04-19T00:02:12.272003Z",
     "shell.execute_reply": "2021-04-19T00:02:12.271441Z"
    },
    "papermill": {
     "duration": 0.04989,
     "end_time": "2021-04-19T00:02:12.272154",
     "exception": false,
     "start_time": "2021-04-19T00:02:12.222264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0040581b-f1f2-4fbe-b043-b6bfea5404bb</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0339 eNqtVL0OgyAQfiVIz4TBoYODiVdKE2odGDqYR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0173029a-161d-40ef-af28-2342915b22fb</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 0.0002 eNq9VMEKwjAM/aVQsE7ZRSgbCKVzh1mnVK1zj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>020a29cf-2c24-478b-8603-c22a90dc3e31</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 0.0104 eNq1lltvqzAMgP8SDtmZtKcjHWlSN+KulG3QJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fea47298-266a-4cf4-93bd-55d1bcc2fc7d</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 0.0048 eNqFUMEOgjAM/aU3tzijN02IIxtDEhJPgEajJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ff069fa2-d948-408e-91b3-034cfea428d1</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 0.0307 eNoLCk2KMMoxDMkzMoCBNL8gowh/ONcrycAFz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ff23eea9-4bbe-42af-a8da-9ae16321fc6d</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0010 eNq9ksFqwzAMhl8pauPNHTkMVmjxGkUwH3Qwt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  ImageWidth  ImageHeight  \\\n",
       "0  0040581b-f1f2-4fbe-b043-b6bfea5404bb        2048         2048   \n",
       "1  0173029a-161d-40ef-af28-2342915b22fb        3072         3072   \n",
       "2  020a29cf-2c24-478b-8603-c22a90dc3e31        1728         1728   \n",
       "3  fea47298-266a-4cf4-93bd-55d1bcc2fc7d        1728         1728   \n",
       "4  ff069fa2-d948-408e-91b3-034cfea428d1        3072         3072   \n",
       "5  ff23eea9-4bbe-42af-a8da-9ae16321fc6d        2048         2048   \n",
       "\n",
       "                                    PredictionString  \n",
       "0  0 0.0339 eNqtVL0OgyAQfiVIz4TBoYODiVdKE2odGDqYR...  \n",
       "1  0 0.0002 eNq9VMEKwjAM/aVQsE7ZRSgbCKVzh1mnVK1zj...  \n",
       "2  0 0.0104 eNq1lltvqzAMgP8SDtmZtKcjHWlSN+KulG3QJ...  \n",
       "3  0 0.0048 eNqFUMEOgjAM/aU3tzijN02IIxtDEhJPgEajJ...  \n",
       "4  0 0.0307 eNoLCk2KMMoxDMkzMoCBNL8gowh/ONcrycAFz...  \n",
       "5  0 0.0010 eNq9ksFqwzAMhl8pauPNHTkMVmjxGkUwH3Qwt...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ss_df = ss_df.merge(sub_df, how=\"left\", on=\"ID\")\n",
    "ss_df[\"PredictionString\"] = ss_df.apply(create_pred_col, axis=1)\n",
    "ss_df = ss_df.drop(columns=[\"PredictionString_x\", \"PredictionString_y\"])\n",
    "display(ss_df)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T00:02:12.329900Z",
     "iopub.status.busy": "2021-04-19T00:02:12.329114Z",
     "iopub.status.idle": "2021-04-19T00:02:58.196119Z",
     "shell.execute_reply": "2021-04-19T00:02:58.195488Z"
    },
    "papermill": {
     "duration": 45.907266,
     "end_time": "2021-04-19T00:02:58.196294",
     "exception": false,
     "start_time": "2021-04-19T00:02:12.289028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 22s 22s/step\n"
     ]
    }
   ],
   "source": [
    "sub_df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n",
    "\n",
    "def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n",
    "    def decode(path):\n",
    "        file_bytes = tf.io.read_file(path)\n",
    "        if ext == 'png':\n",
    "            img = tf.image.decode_png(file_bytes, channels=3)\n",
    "        elif ext in ['jpg', 'jpeg']:\n",
    "            img = tf.image.decode_jpeg(file_bytes, channels=3)\n",
    "        else:\n",
    "            raise ValueError(\"Image extension not supported\")\n",
    "\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        img = tf.image.resize(img, target_size)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def decode_with_labels(path, label):\n",
    "        return decode(path), label\n",
    "\n",
    "    return decode_with_labels if with_labels else decode\n",
    "\n",
    "\n",
    "def build_augmenter(with_labels=True):\n",
    "    def augment(img):\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "        return img\n",
    "\n",
    "    def augment_with_labels(img, label):\n",
    "        return augment(img), label\n",
    "\n",
    "    return augment_with_labels if with_labels else augment\n",
    "\n",
    "\n",
    "def build_dataset(paths, labels=None, bsize=32, cache=True,\n",
    "                  decode_fn=None, augment_fn=None,\n",
    "                  augment=True, repeat=True, shuffle=1024, \n",
    "                  cache_dir=\"\"):\n",
    "    if cache_dir != \"\" and cache is True:\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    if decode_fn is None:\n",
    "        decode_fn = build_decoder(labels is not None)\n",
    "\n",
    "    if augment_fn is None:\n",
    "        augment_fn = build_augmenter(labels is not None)\n",
    "\n",
    "    AUTO = tf.data.experimental.AUTOTUNE\n",
    "    slices = paths if labels is None else (paths, labels)\n",
    "\n",
    "    dset = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n",
    "    dset = dset.cache(cache_dir) if cache else dset\n",
    "    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n",
    "    dset = dset.repeat() if repeat else dset\n",
    "    dset = dset.shuffle(shuffle) if shuffle else dset\n",
    "    dset = dset.batch(bsize).prefetch(AUTO)\n",
    "\n",
    "    return dset\n",
    "\n",
    "COMPETITION_NAME = \"hpa-single-cell-image-classification\"\n",
    "strategy = tf.distribute.get_strategy()\n",
    "BATCH_SIZE = strategy.num_replicas_in_sync * 16\n",
    "\n",
    "IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)\n",
    "\n",
    "load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n",
    "sub_df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n",
    "sub_df = ss_df.copy()\n",
    "\n",
    "sub_df = sub_df.drop(sub_df.columns[1:],axis=1)\n",
    "\n",
    "for i in range(19):\n",
    "    sub_df[f'{i}'] = pd.Series(np.zeros(sub_df.shape[0]))\n",
    "\n",
    "\n",
    "test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_green.png'\n",
    "# Get the multi-labels\n",
    "label_cols = sub_df.columns[1:]\n",
    "\n",
    "test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]))\n",
    "dtest = build_dataset(\n",
    "    test_paths, bsize=BATCH_SIZE, repeat=False, \n",
    "    shuffle=False, augment=False, cache=False,\n",
    "    decode_fn=test_decoder\n",
    ")\n",
    "\n",
    "with strategy.scope():\n",
    "    model = tf.keras.models.load_model(auxiliary_model)\n",
    "\n",
    "sub_df[label_cols] = model.predict(dtest, verbose=1)\n",
    "\n",
    "sub_df.head()\n",
    "\n",
    "ss_df = pd.merge(ss_df, sub_df, on = 'ID', how = 'left')\n",
    "\n",
    "for i in range(ss_df.shape[0]):\n",
    "    if ss_df.loc[i,'PredictionString'] == '0 1 eNoLCAgIMAEABJkBdQ==':\n",
    "        continue\n",
    "    a = ss_df.loc[i,'PredictionString']\n",
    "    b = a.split()\n",
    "    for j in range(int(len(a.split())/3)):\n",
    "        for k in range(19):\n",
    "            if int(b[0 + 3 * j]) == k:\n",
    "\n",
    "                c = b[0 + 3 * j + 1]               \n",
    "                b[0 + 3 * j + 1] = str(ss_df.loc[i,f'{k}'] * 0.6 + float(c) * 0.4)\n",
    "\n",
    "    ss_df.loc[i,'PredictionString'] = ' '.join(b)\n",
    "\n",
    "ss_df = ss_df[['ID','ImageWidth','ImageHeight','PredictionString']]\n",
    "ss_df.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-19T00:02:58.236460Z",
     "iopub.status.busy": "2021-04-19T00:02:58.235787Z",
     "iopub.status.idle": "2021-04-19T00:02:58.256346Z",
     "shell.execute_reply": "2021-04-19T00:02:58.257013Z"
    },
    "papermill": {
     "duration": 0.042049,
     "end_time": "2021-04-19T00:02:58.257195",
     "exception": false,
     "start_time": "2021-04-19T00:02:58.215146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0040581b-f1f2-4fbe-b043-b6bfea5404bb</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.06094576412200928 eNqtVL0OgyAQfiVIz4TBoYOD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0173029a-161d-40ef-af28-2342915b22fb</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 0.06599916680335997 eNq9VMEKwjAM/aVQsE7ZRSgb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>020a29cf-2c24-478b-8603-c22a90dc3e31</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 0.005497885856628418 eNq1lltvqzAMgP8SDtmZtKc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fea47298-266a-4cf4-93bd-55d1bcc2fc7d</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 0.011608425064086913 eNqFUMEOgjAM/aU3tzijN02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ff069fa2-d948-408e-91b3-034cfea428d1</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 0.5375168211746215 eNoLCk2KMMoxDMkzMoCBNL8go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ff23eea9-4bbe-42af-a8da-9ae16321fc6d</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0007910481929779053 eNq9ksFqwzAMhl8pauPNHT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  ImageWidth  ImageHeight  \\\n",
       "0  0040581b-f1f2-4fbe-b043-b6bfea5404bb        2048         2048   \n",
       "1  0173029a-161d-40ef-af28-2342915b22fb        3072         3072   \n",
       "2  020a29cf-2c24-478b-8603-c22a90dc3e31        1728         1728   \n",
       "3  fea47298-266a-4cf4-93bd-55d1bcc2fc7d        1728         1728   \n",
       "4  ff069fa2-d948-408e-91b3-034cfea428d1        3072         3072   \n",
       "5  ff23eea9-4bbe-42af-a8da-9ae16321fc6d        2048         2048   \n",
       "\n",
       "                                    PredictionString  \n",
       "0  0 0.06094576412200928 eNqtVL0OgyAQfiVIz4TBoYOD...  \n",
       "1  0 0.06599916680335997 eNq9VMEKwjAM/aVQsE7ZRSgb...  \n",
       "2  0 0.005497885856628418 eNq1lltvqzAMgP8SDtmZtKc...  \n",
       "3  0 0.011608425064086913 eNqFUMEOgjAM/aU3tzijN02...  \n",
       "4  0 0.5375168211746215 eNoLCk2KMMoxDMkzMoCBNL8go...  \n",
       "5  0 0.0007910481929779053 eNq9ksFqwzAMhl8pauPNHT...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 377.725904,
   "end_time": "2021-04-19T00:03:01.306557",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-18T23:56:43.580653",
   "version": "2.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "078de078f5ed4e01b7e0a461a5562179": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0a769b2ef3614a7a82b47854270ca7e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bd6a336e0847497ebe80a7d4cbdd132a",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_62442ad1f5ff467193508d4320eeb7ec",
       "value": 1.0
      }
     },
     "0ea340aec8d8430498778bf596b96703": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_19e46d8e2a1a4835b23deff37c4fc60b",
       "placeholder": "​",
       "style": "IPY_MODEL_ffb9038a93b041afb9d3d103f4efe543",
       "value": "100%"
      }
     },
     "13e997a2e0d14e2ba6cf151382109b5b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19e46d8e2a1a4835b23deff37c4fc60b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2034b6d41d5a45f4ae0f8346d7961dbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_214f2aa21207469ab72748bb6915fa74",
       "placeholder": "​",
       "style": "IPY_MODEL_fb4d53536d4e49b7b130a4ce99c6e11f",
       "value": " 1/1 [00:51&lt;00:00, 51.46s/it]"
      }
     },
     "214f2aa21207469ab72748bb6915fa74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "242be718362948b7ad03301607d6cdd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2a11fc188af0478a82cd3e4fcc396372": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ddb3d01c90d47038cb66cf90bfd4670": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_13e997a2e0d14e2ba6cf151382109b5b",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_73cf4e40d770487189978ec5a81de925",
       "value": 1.0
      }
     },
     "358703b3d11f4e3ba7273cd5435e60b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bb4a29f04d9f4c0fa858b9992f69e0d3",
       "placeholder": "​",
       "style": "IPY_MODEL_4f4672a62f1c41dbaad62fdda70a55e0",
       "value": " 1/1 [01:11&lt;00:00, 71.49s/it]"
      }
     },
     "37ce9e32a0494f63b84ee64b719f9e3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2a11fc188af0478a82cd3e4fcc396372",
       "placeholder": "​",
       "style": "IPY_MODEL_c4ccd267a55e4b7c965f7325ae690f54",
       "value": "100%"
      }
     },
     "37f9eb0a569b4503bc413b1e70ce675b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_37ce9e32a0494f63b84ee64b719f9e3a",
        "IPY_MODEL_0a769b2ef3614a7a82b47854270ca7e3",
        "IPY_MODEL_358703b3d11f4e3ba7273cd5435e60b8"
       ],
       "layout": "IPY_MODEL_cf5e9b6b3f3b477a85108596c6a6777f"
      }
     },
     "3a8b4f0d94934f7d8a0dcc2ec71bd664": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_60df557b37254d0aab25abcfdb987802",
        "IPY_MODEL_e6182370cd614e87957c0e1f59728e1b",
        "IPY_MODEL_869b21ed56a543f8a8807b959b301358"
       ],
       "layout": "IPY_MODEL_8d3b0763092e498db6674279154ac991"
      }
     },
     "4f4672a62f1c41dbaad62fdda70a55e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "60df557b37254d0aab25abcfdb987802": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e14d53aabe854204bb6e268e75494c97",
       "placeholder": "​",
       "style": "IPY_MODEL_078de078f5ed4e01b7e0a461a5562179",
       "value": "100%"
      }
     },
     "62442ad1f5ff467193508d4320eeb7ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "73cf4e40d770487189978ec5a81de925": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7580b5272e914c46ac8b1a1b151a2ac6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0ea340aec8d8430498778bf596b96703",
        "IPY_MODEL_2ddb3d01c90d47038cb66cf90bfd4670",
        "IPY_MODEL_2034b6d41d5a45f4ae0f8346d7961dbf"
       ],
       "layout": "IPY_MODEL_8f689ab1e2414da4ac155e4a37f9d6f5"
      }
     },
     "841876ab3e15456caaed6ab669d2859e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "869b21ed56a543f8a8807b959b301358": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_841876ab3e15456caaed6ab669d2859e",
       "placeholder": "​",
       "style": "IPY_MODEL_242be718362948b7ad03301607d6cdd9",
       "value": " 1/1 [00:36&lt;00:00, 36.15s/it]"
      }
     },
     "8d3b0763092e498db6674279154ac991": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f689ab1e2414da4ac155e4a37f9d6f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "985d2a4718ce45b88e6ec97a9ba02e48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bb4a29f04d9f4c0fa858b9992f69e0d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bd6a336e0847497ebe80a7d4cbdd132a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4ccd267a55e4b7c965f7325ae690f54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cf5e9b6b3f3b477a85108596c6a6777f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1467f9b688d4e6b90baa11baa8a1034": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e14d53aabe854204bb6e268e75494c97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6182370cd614e87957c0e1f59728e1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e1467f9b688d4e6b90baa11baa8a1034",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_985d2a4718ce45b88e6ec97a9ba02e48",
       "value": 1.0
      }
     },
     "fb4d53536d4e49b7b130a4ce99c6e11f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ffb9038a93b041afb9d3d103f4efe543": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
